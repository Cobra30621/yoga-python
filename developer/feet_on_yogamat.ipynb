{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 偵測瑜珈墊在腳的位置\n",
    "\n",
    "- 詳細介紹可參考[論文](https://docs.google.com/document/d/1sWPlbKvfi4x-Idih0DI4toHYrIhyDv6y/edit?usp=sharing&ouid=114571548892193624282&rtpof=true&sd=true) : 3.1. 瑜珈墊腳座標校正 \n",
    "\n",
    "### 流程\n",
    "\n",
    "![image](https://hackmd.io/_uploads/rJhu2ozIC.png)\n",
    "\n",
    "1. 抓到瑜珈墊在鏡頭的座標點\n",
    "    - 預設: [[0.9, 0.97],[0.1, 0.97],[0.15, 0.76],[0.85, 0.76]]\n",
    "    - 實際抓: YogaMatRangeGetter.py\n",
    "    - 目前專案是使用預設抓法， YogaMatRangeGetter.py 不一定穩定\n",
    "2. 使用瑜伽墊的四個座標點，來建立透視變換的轉換矩陣\n",
    "3. 將雙腳投影到瑜珈墊座標\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aabf249f4914444d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. python class 方置區\n",
    "\n",
    "此區放置之後回移植到 android studio 的 python 檔案\n",
    "在完成研究後，記得把程式碼複製上去\n",
    "\n",
    "- ScoreCalculator.py"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "57560d6e931c95e6"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from FeetData import FeetData\n",
    "import AngleNodeDef\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from YogaMatRangeGetter import YogaMatRangeGetter\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 負責將人體骨架的腳座標點，轉換成瑜珈墊上面的點\n",
    "# 轉至技術介紹: https://blog.csdn.net/guduruyu/article/details/72518340\n",
    "class YogaMatProcessor:\n",
    "    def __init__(self, use_default_matrix=True):\n",
    "        # 鏡頭的座標位置\n",
    "        self.camera_flat_points = np.array([[1, 1], [0, 1], [0, 0], [1, 0]], dtype=np.float32)\n",
    "        # 預設瑜珈墊在鏡頭的座標\n",
    "        default_mat_point = np.array([[0.9, 0.97],\n",
    "                                      [0.1, 0.97],\n",
    "                                      [0.15, 0.76],\n",
    "                                      [0.85, 0.76]], dtype=np.float32)\n",
    "\n",
    "        # 使用預設的轉至矩陣\n",
    "        self.use_default_matrix = use_default_matrix\n",
    "        # 轉換矩陣\n",
    "        self.transform_matrix = cv2.getPerspectiveTransform(default_mat_point,\n",
    "                                                            self.camera_flat_points)\n",
    "        self.feet_data = FeetData()\n",
    "\n",
    "    # 產生腳的資料\n",
    "    def generate_feet_data(self, r_point2d, r_point3d):\n",
    "        # 將骨架資料根據 python 格式進行轉換\n",
    "        point2d, point3d = self.__handle_skeleton_point(r_point2d, r_point3d)\n",
    "\n",
    "        # 檢查骨架是否為空\n",
    "        if self.__contain_point(point2d, point3d):\n",
    "            # 取得腳的 2d 座標\n",
    "            feet_points = self.__get_feet_points(point2d)\n",
    "            # 將腳的座標進行轉換\n",
    "            transform_points = self.transform_point(feet_points)\n",
    "\n",
    "            # 創建腳的資料\n",
    "            left_feet, right_feet = transform_points[0], transform_points[1]\n",
    "            self.feet_data.set_point(left_feet, right_feet)\n",
    "        else:\n",
    "            self.feet_data.set_point(None, None)\n",
    "\n",
    "        return self.feet_data.to_dict()\n",
    "\n",
    "    # 產稱瑜珈墊的轉至矩陣\n",
    "    def generate_transform_matrix_with_image(self, image):\n",
    "        range_getter = YogaMatRangeGetter()\n",
    "        max_contour, approx, mat_points, contours, mask = range_getter.generate_mat_range(image, True)\n",
    "\n",
    "        self.generate_transform_matrix(mat_points)\n",
    "\n",
    "    # 產稱瑜珈墊的轉至矩陣\n",
    "    def generate_transform_matrix(self, unit_points):\n",
    "        is_4_point = len(unit_points[0]) == 4\n",
    "\n",
    "        transform_matrix = cv2.getPerspectiveTransform(unit_points, self.camera_flat_points) if is_4_point else []\n",
    "\n",
    "        if is_4_point:\n",
    "            self.transform_matrix = transform_matrix\n",
    "\n",
    "    # 將鏡頭中的座標點，轉換到瑜珈墊上面\n",
    "    def transform_point(self, input_points):\n",
    "        transformed_points = [\n",
    "            cv2.perspectiveTransform(np.array([np.float32([p])]), self.transform_matrix)[0][0] for p\n",
    "            in input_points]\n",
    "\n",
    "        return transformed_points\n",
    "\n",
    "    # 將骨架資料根據 python 格式進行轉換\n",
    "    def __handle_skeleton_point(self, r_point2d, r_point3d):\n",
    "        point3d = [[r_point3d.get(i).get(j) for j in range(3)] for i in range(r_point3d.size())]\n",
    "        point2d = [[r_point2d.get(i).get(j) for j in range(2)] for i in range(r_point2d.size())]\n",
    "\n",
    "        return point2d, point3d\n",
    "\n",
    "    # 檢查骨架是否為空\n",
    "    def __contain_point(self, point2d, point3d):\n",
    "        return not isinstance(point2d, int) and not isinstance(point3d, int)\n",
    "\n",
    "    # 從 MediaPipe 的點中，取得在鏡頭中腳的點\n",
    "    def __get_feet_points(self, point2d):\n",
    "        return [[point2d[AngleNodeDef.LEFT_HEEL][0], point2d[AngleNodeDef.LEFT_HEEL][1]],\n",
    "                [point2d[AngleNodeDef.RIGHT_HEEL][0], point2d[AngleNodeDef.RIGHT_HEEL][1]]]\n",
    "\n",
    "    # 取得腳的資料\n",
    "    def get_left_foot_x(self):\n",
    "        # 取得 left_foot 的 x 座標\n",
    "        return self.feet_data.left_foot[0] if self.feet_data.left_foot is not None else - 999999\n",
    "\n",
    "    def get_left_foot_y(self):\n",
    "        # 取得 left_foot 的 y 座標\n",
    "        return self.feet_data.left_foot[1] if self.feet_data.left_foot is not None else - 999999\n",
    "\n",
    "    def get_right_foot_x(self):\n",
    "        # 取得 right_foot 的 x 座標\n",
    "        return self.feet_data.right_foot[0] if self.feet_data.right_foot is not None else - 999999\n",
    "\n",
    "    def get_right_foot_y(self):\n",
    "        # 取得 right_foot 的 y 座標\n",
    "        return self.feet_data.right_foot[1] if self.feet_data.right_foot is not None else - 999999"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-21T07:43:35.967358400Z",
     "start_time": "2024-06-21T07:43:35.778356Z"
    }
   },
   "id": "f360b96d649f2419"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def get_feet_points(point2d):\n",
    "    if not isinstance(point2d, int):\n",
    "        left_point = point2d[AngleNodeDef.LEFT_HEEL]\n",
    "        right_point = point2d[AngleNodeDef.RIGHT_HEEL]\n",
    "        return [[left_point.x, left_point.y], [right_point.x, right_point.y]]\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "#  將輸入的座標乘以 height 和 width\n",
    "def scale_coordinates(input_point, width, height):\n",
    "    return [[point[0] * width, point[1] * height] for point in input_point]\n",
    "\n",
    "def inverse_transform_coordinates(coordinates, width, height):\n",
    "    \"\"\"\n",
    "    將輸入的座標除以 height 和 width，返回反向轉換後的座標。\n",
    "\n",
    "    Args:\n",
    "        coordinates (numpy.ndarray): 二維座標陣列，每個元素都是一個座標點的陣列，如[[x1, y1], [x2, y2], ...]\n",
    "        height (float): 高度\n",
    "        width (float): 寬度\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: 反向轉換後的座標陣列，格式與輸入相同\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    將輸入的座標除以 height 和 width，返回反向轉換後的座標，並四捨五入到小數第二位。\n",
    "\n",
    "    Args:\n",
    "        coordinates (numpy.ndarray): 二維座標陣列，每個元素都是一個座標點的列表，如[[x1, y1], [x2, y2], ...]\n",
    "        height (float): 高度\n",
    "        width (float): 寬度\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: 反向轉換後的座標陣列，格式與輸入相同\n",
    "    \"\"\"\n",
    "    transformed_coordinates = coordinates / np.array([width, height], dtype=np.float32)\n",
    "    return np.round(transformed_coordinates, decimals=2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-21T07:52:14.903433300Z",
     "start_time": "2024-06-21T07:52:14.890429100Z"
    }
   },
   "id": "fa70ec10d5af71ae"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280 720\n",
      "<__main__.YogaMatProcessor object at 0x000002F80CC47910>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 70\u001B[0m\n\u001B[0;32m     65\u001B[0m     cv2\u001B[38;5;241m.\u001B[39mdestroyAllWindows()\n\u001B[0;32m     69\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m---> 70\u001B[0m     \u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[9], line 51\u001B[0m, in \u001B[0;36mmain\u001B[1;34m()\u001B[0m\n\u001B[0;32m     49\u001B[0m point2d, point3d \u001B[38;5;241m=\u001B[39m get_Mediapipe_point(image)\n\u001B[0;32m     50\u001B[0m \u001B[38;5;28mprint\u001B[39m(image_processor)\n\u001B[1;32m---> 51\u001B[0m max_contour, approx \u001B[38;5;241m=\u001B[39m image_processor\u001B[38;5;241m.\u001B[39mgenerate_transform_matrix(image)\n\u001B[0;32m     53\u001B[0m input_point \u001B[38;5;241m=\u001B[39m image_processor\u001B[38;5;241m.\u001B[39mget_feet_points(point2d)\n\u001B[0;32m     55\u001B[0m feet_points_on_mat_dict \u001B[38;5;241m=\u001B[39m image_processor\u001B[38;5;241m.\u001B[39mget_feet_points_on_mat(point2d, point3d)\n",
      "\u001B[1;31mTypeError\u001B[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "\n",
    "from develop_tool import  get_Mediapipe_point, resize_image\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 劃出在攝影機中，瑜珈墊框起來的狀況\n",
    "def draw_camera_result(image, contours, max_contour, approx, raw_points):\n",
    "    image_copy = image.copy()\n",
    "\n",
    "    for contour in contours:\n",
    "        cv2.drawContours(image_copy, [contour], 0, (255, 0, 0), 2)\n",
    "        \n",
    "    cv2.drawContours(image_copy, [max_contour], 0, (0, 255, 0), 2)\n",
    "    cv2.drawContours(image_copy, [approx], -1, (0, 0, 255), 2)\n",
    "\n",
    "    # Iterate through the points with corresponding colors\n",
    "    for i, raw_point in enumerate(raw_points):\n",
    "        # Draw on the original image\n",
    "        cv2.circle(image_copy, tuple(map(int, raw_point)), 10, colors[i], thickness=cv2.FILLED)\n",
    "    \n",
    "    return image_copy\n",
    "\n",
    "\n",
    "colors = [(0,0,255), (255, 0, 0)]\n",
    "\n",
    "range_getter = YogaMatRangeGetter()\n",
    "mat_processor = YogaMatProcessor()\n",
    "\n",
    "lower_green = np.array([25, 20, 20])\n",
    "upper_green = np.array([110, 255, 255])\n",
    "\n",
    "range_getter.set_mask(lower_green, upper_green)\n",
    "\n",
    "\n",
    "def display(image, file_name):\n",
    "    height = len(image)\n",
    "    width = len(image[0])\n",
    "    # get point\n",
    "    point2d, point3d = get_Mediapipe_point(image, False)\n",
    "    input_point = get_feet_points(point2d)\n",
    "    scale_point = scale_coordinates(input_point, width, height)\n",
    "    print(\"input\", input_point, \"scale\", scale_point)\n",
    "    \n",
    "    # create transform_matrix\n",
    "    max_contour, approx, unit_point, contours , mask = range_getter.generate_mat_range(image)\n",
    "    unit_points = inverse_transform_coordinates(unit_point, width, height)\n",
    "    \n",
    "    mat_processor.generate_transform_matrix(unit_points)\n",
    "    transform_point = mat_processor.transform_point(input_point)\n",
    "    \n",
    "    user_frame =   draw_camera_result(image, [max_contour], max_contour, approx, scale_point)\n",
    "    scale_transform_point = scale_coordinates(transform_point, width, height)\n",
    "    # print(\"input_point\", input_point)\n",
    "    # print(\"scale_point\", scale_point)\n",
    "    # print(\"transform_point\", transform_point)\n",
    "    # print(\"scale\", scale_transform_point)\n",
    "    yoga_mat_image = draw_yoga_mat_result(height, width, scale_transform_point)\n",
    "    # cv2.drawContours(image, contours, -1, (0,255,0), 3)\n",
    "    \n",
    "    full_image = cv2.hconcat([user_frame, yoga_mat_image])\n",
    "    \n",
    "    cv2.imshow('image' + file_name , full_image)\n",
    "    # cv2.imshow('counter', mask)\n",
    "    \n",
    "    show_transform_mat(image, scale_point)\n",
    "\n",
    "def show_transform_mat(image, input_point):\n",
    "    # Create mat image\n",
    "    h = 300\n",
    "    w = 800\n",
    "    \n",
    "    max_contour, approx, unit_point, contours , mask = range_getter.generate_mat_range(image)\n",
    "    \n",
    "    mat_processor.camera_flat_points = np.array([[w, h], [0, h], [0, 0], [w, 0]], dtype=np.float32)\n",
    "    mat_processor.generate_transform_matrix(unit_point)\n",
    "    transform_image = cv2.warpPerspective(image, mat_processor.transform_matrix, (w, h))\n",
    "    transform_point = mat_processor.transform_point(input_point)\n",
    "    print(\"unit_point\", unit_point)\n",
    "    print(\"transform\", transform_point)\n",
    "    \n",
    "    for i, raw_point in enumerate(transform_point):\n",
    "        # Draw on the original image\n",
    "        cv2.circle(transform_image, tuple(map(int, raw_point)), 10, colors[i], thickness=cv2.FILLED)\n",
    "        \n",
    "    cv2.imshow(\"transform_image\", transform_image)\n",
    "\n",
    "\n",
    "def show_video():\n",
    "    video_path = \"data/video/you.mp4\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Video end\")\n",
    "            break\n",
    "            \n",
    "        display(frame, \"video\")\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "            \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "def show_image():\n",
    "    # \"mat_test2.jpg\"  \"ewang.png\" \"cobra.png\"\n",
    "    image_names = [\"ewang.png\"]\n",
    "    image_path = \"data/image/\"\n",
    "    \n",
    "    for name in image_names:\n",
    "        image = cv2.imread(image_path + name, cv2.IMREAD_UNCHANGED)\n",
    "        display(image, name)\n",
    "\n",
    "    # 按下任意鍵則關閉所有視窗\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    show_image()\n",
    "    # show_video()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-21T07:49:26.803437700Z",
     "start_time": "2024-06-21T07:49:26.658425100Z"
    }
   },
   "id": "c1ea27f80b92d5f4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e69fe5f723611bdb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
