{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 偵測瑜珈墊在腳的位置\n",
    "\n",
    "- 詳細介紹可參考[論文](https://docs.google.com/document/d/1sWPlbKvfi4x-Idih0DI4toHYrIhyDv6y/edit?usp=sharing&ouid=114571548892193624282&rtpof=true&sd=true) : 3.1. 瑜珈墊腳座標校正 \n",
    "\n",
    "### 流程\n",
    "\n",
    "![image](https://hackmd.io/_uploads/rJhu2ozIC.png)\n",
    "\n",
    "1. 抓到瑜珈墊在鏡頭的座標點\n",
    "    - 預設: [[0.9, 0.97],[0.1, 0.97],[0.15, 0.76],[0.85, 0.76]]\n",
    "    - 實際抓: YogaMatRangeGetter.py\n",
    "    - 目前專案是使用預設抓法， YogaMatRangeGetter.py 不一定穩定\n",
    "2. 使用瑜伽墊的四個座標點，來建立透視變換的轉換矩陣\n",
    "3. 將雙腳投影到瑜珈墊座標\n",
    "\n",
    "### 1. python class 方置區\n",
    "\n",
    "此區放置之後回移植到 android studio 的 python 檔案\n",
    "在完成研究後，記得把程式碼複製上去\n",
    "\n",
    "- ScoreCalculator.py"
   ],
   "id": "fa2a4cb5d46b1e5a"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-17T14:22:42.394031Z",
     "start_time": "2024-09-17T14:22:42.233967Z"
    }
   },
   "source": [
    "from FeetData import FeetData\n",
    "import AngleNodeDef\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from YogaMatRangeGetter import YogaMatRangeGetter\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 負責將人體骨架的腳座標點，轉換成瑜珈墊上面的點\n",
    "# 轉至技術介紹: https://blog.csdn.net/guduruyu/article/details/72518340\n",
    "class YogaMatProcessor:\n",
    "    def __init__(self, use_default_matrix=True):\n",
    "        # 鏡頭的座標位置\n",
    "        self.camera_flat_points = np.array([[1, 1], [0, 1], [0, 0], [1, 0]], dtype=np.float32)\n",
    "        # 預設瑜珈墊在鏡頭的座標\n",
    "        default_mat_point = np.array([[0.9, 0.97],\n",
    "                                      [0.1, 0.97],\n",
    "                                      [0.15, 0.76],\n",
    "                                      [0.85, 0.76]], dtype=np.float32)\n",
    "\n",
    "        # 使用預設的轉至矩陣\n",
    "        self.use_default_matrix = use_default_matrix\n",
    "        # 轉換矩陣\n",
    "        self.transform_matrix = cv2.getPerspectiveTransform(default_mat_point,\n",
    "                                                            self.camera_flat_points)\n",
    "        self.feet_data = FeetData()\n",
    "\n",
    "    # 產生腳的資料\n",
    "    def generate_feet_data(self, r_point2d, r_point3d):\n",
    "        # 將骨架資料根據 python 格式進行轉換\n",
    "        point2d, point3d = self.__handle_skeleton_point(r_point2d, r_point3d)\n",
    "\n",
    "        # 檢查骨架是否為空\n",
    "        if self.__contain_point(point2d, point3d):\n",
    "            # 取得腳的 2d 座標\n",
    "            feet_points = self.__get_feet_points(point2d)\n",
    "            # 將腳的座標進行轉換\n",
    "            transform_points = self.transform_point(feet_points)\n",
    "\n",
    "            # 創建腳的資料\n",
    "            left_feet, right_feet = transform_points[0], transform_points[1]\n",
    "            self.feet_data.set_point(left_feet, right_feet)\n",
    "        else:\n",
    "            self.feet_data.set_point(None, None)\n",
    "\n",
    "        return self.feet_data.to_dict()\n",
    "\n",
    "    # 產稱瑜珈墊的轉至矩陣\n",
    "    def generate_transform_matrix_with_image(self, image):\n",
    "        range_getter = YogaMatRangeGetter()\n",
    "        max_contour, approx, mat_points, contours, mask = range_getter.generate_mat_range(image, True)\n",
    "\n",
    "        self.generate_transform_matrix(mat_points)\n",
    "\n",
    "    # 產稱瑜珈墊的轉至矩陣\n",
    "    def generate_transform_matrix(self, unit_points):\n",
    "        is_4_point = len(unit_points[0]) == 4\n",
    "\n",
    "        transform_matrix = cv2.getPerspectiveTransform(unit_points, self.camera_flat_points) if is_4_point else []\n",
    "\n",
    "        if is_4_point:\n",
    "            self.transform_matrix = transform_matrix\n",
    "\n",
    "    # 將鏡頭中的座標點，轉換到瑜珈墊上面\n",
    "    def transform_point(self, input_points):\n",
    "        transformed_points = [\n",
    "            cv2.perspectiveTransform(np.array([np.float32([p])]), self.transform_matrix)[0][0] for p\n",
    "            in input_points]\n",
    "\n",
    "        return transformed_points\n",
    "\n",
    "    # 將骨架資料根據 python 格式進行轉換\n",
    "    def __handle_skeleton_point(self, r_point2d, r_point3d):\n",
    "        point3d = [[r_point3d.get(i).get(j) for j in range(3)] for i in range(r_point3d.size())]\n",
    "        point2d = [[r_point2d.get(i).get(j) for j in range(2)] for i in range(r_point2d.size())]\n",
    "\n",
    "        return point2d, point3d\n",
    "\n",
    "    # 檢查骨架是否為空\n",
    "    def __contain_point(self, point2d, point3d):\n",
    "        return not isinstance(point2d, int) and not isinstance(point3d, int)\n",
    "\n",
    "    # 從 MediaPipe 的點中，取得在鏡頭中腳的點\n",
    "    def __get_feet_points(self, point2d):\n",
    "        return [[point2d[AngleNodeDef.LEFT_HEEL][0], point2d[AngleNodeDef.LEFT_HEEL][1]],\n",
    "                [point2d[AngleNodeDef.RIGHT_HEEL][0], point2d[AngleNodeDef.RIGHT_HEEL][1]]]\n",
    "\n",
    "    # 取得腳的資料\n",
    "    def get_left_foot_x(self):\n",
    "        # 取得 left_foot 的 x 座標\n",
    "        return self.feet_data.left_foot[0] if self.feet_data.left_foot is not None else - 999999\n",
    "\n",
    "    def get_left_foot_y(self):\n",
    "        # 取得 left_foot 的 y 座標\n",
    "        return self.feet_data.left_foot[1] if self.feet_data.left_foot is not None else - 999999\n",
    "\n",
    "    def get_right_foot_x(self):\n",
    "        # 取得 right_foot 的 x 座標\n",
    "        return self.feet_data.right_foot[0] if self.feet_data.right_foot is not None else - 999999\n",
    "\n",
    "    def get_right_foot_y(self):\n",
    "        # 取得 right_foot 的 y 座標\n",
    "        return self.feet_data.right_foot[1] if self.feet_data.right_foot is not None else - 999999"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T14:22:50.034643Z",
     "start_time": "2024-09-17T14:22:50.021993Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_feet_points(point2d):\n",
    "    if not isinstance(point2d, int):\n",
    "        left_point = point2d[AngleNodeDef.LEFT_HEEL]\n",
    "        right_point = point2d[AngleNodeDef.RIGHT_HEEL]\n",
    "        return [[left_point.x, left_point.y], [right_point.x, right_point.y]]\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "#  將輸入的座標乘以 height 和 width\n",
    "def scale_coordinates(input_point, width, height):\n",
    "    return [[point[0] * width, point[1] * height] for point in input_point]\n",
    "\n",
    "def inverse_transform_coordinates(coordinates, width, height):\n",
    "    \"\"\"\n",
    "    將輸入的座標除以 height 和 width，返回反向轉換後的座標。\n",
    "\n",
    "    Args:\n",
    "        coordinates (numpy.ndarray): 二維座標陣列，每個元素都是一個座標點的陣列，如[[x1, y1], [x2, y2], ...]\n",
    "        height (float): 高度\n",
    "        width (float): 寬度\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: 反向轉換後的座標陣列，格式與輸入相同\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    將輸入的座標除以 height 和 width，返回反向轉換後的座標，並四捨五入到小數第二位。\n",
    "\n",
    "    Args:\n",
    "        coordinates (numpy.ndarray): 二維座標陣列，每個元素都是一個座標點的列表，如[[x1, y1], [x2, y2], ...]\n",
    "        height (float): 高度\n",
    "        width (float): 寬度\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: 反向轉換後的座標陣列，格式與輸入相同\n",
    "    \"\"\"\n",
    "    transformed_coordinates = coordinates / np.array([width, height], dtype=np.float32)\n",
    "    return np.round(transformed_coordinates, decimals=2)"
   ],
   "id": "234ba0fc693aa18e",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T14:26:51.523868Z",
     "start_time": "2024-09-17T14:26:44.684185Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from develop_tool import  get_Mediapipe_point, resize_image\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 劃出在攝影機中，瑜珈墊框起來的狀況\n",
    "def draw_camera_result(image, contours, max_contour, approx, raw_points):\n",
    "    image_copy = image.copy()\n",
    "\n",
    "    for contour in contours:\n",
    "        cv2.drawContours(image_copy, [contour], 0, (255, 0, 0), 2)\n",
    "\n",
    "    cv2.drawContours(image_copy, [max_contour], 0, (0, 255, 0), 2)\n",
    "    cv2.drawContours(image_copy, [approx], -1, (0, 0, 255), 2)\n",
    "\n",
    "    # Iterate through the points with corresponding colors\n",
    "    for i, raw_point in enumerate(raw_points):\n",
    "        # Draw on the original image\n",
    "        cv2.circle(image_copy, tuple(map(int, raw_point)), 10, colors[i], thickness=cv2.FILLED)\n",
    "\n",
    "    return image_copy\n",
    "\n",
    "\n",
    "colors = [(0,0,255), (255, 0, 0)]\n",
    "\n",
    "range_getter = YogaMatRangeGetter()\n",
    "mat_processor = YogaMatProcessor()\n",
    "\n",
    "lower_green = np.array([25, 20, 20])\n",
    "upper_green = np.array([110, 255, 255])\n",
    "\n",
    "range_getter.set_mask(lower_green, upper_green)\n",
    "\n",
    "\n",
    "def display(image, file_name):\n",
    "    height = len(image)\n",
    "    width = len(image[0])\n",
    "    # get point\n",
    "    point2d, point3d = get_Mediapipe_point(image)\n",
    "    input_point = get_feet_points(point2d)\n",
    "    scale_point = scale_coordinates(input_point, width, height)\n",
    "    print(\"input\", input_point, \"scale\", scale_point)\n",
    "\n",
    "    # create transform_matrix\n",
    "    max_contour, approx, unit_point, contours , mask = range_getter.generate_mat_range(image)\n",
    "    unit_points = inverse_transform_coordinates(unit_point, width, height)\n",
    "\n",
    "    mat_processor.generate_transform_matrix(unit_points)\n",
    "    transform_point = mat_processor.transform_point(input_point)\n",
    "\n",
    "    user_frame =   draw_camera_result(image, [max_contour], max_contour, approx, scale_point)\n",
    "    scale_transform_point = scale_coordinates(transform_point, width, height)\n",
    "\n",
    "    show_transform_mat(image, scale_point)\n",
    "\n",
    "def show_transform_mat(image, input_point):\n",
    "    # Create mat image\n",
    "    h = 300\n",
    "    w = 800\n",
    "\n",
    "    max_contour, approx, unit_point, contours , mask = range_getter.generate_mat_range(image)\n",
    "\n",
    "    mat_processor.camera_flat_points = np.array([[w, h], [0, h], [0, 0], [w, 0]], dtype=np.float32)\n",
    "    mat_processor.generate_transform_matrix(unit_point)\n",
    "    transform_image = cv2.warpPerspective(image, mat_processor.transform_matrix, (w, h))\n",
    "    transform_point = mat_processor.transform_point(input_point)\n",
    "    print(\"unit_point\", unit_point)\n",
    "    print(\"transform\", transform_point)\n",
    "\n",
    "    for i, raw_point in enumerate(transform_point):\n",
    "        # Draw on the original image\n",
    "        cv2.circle(transform_image, tuple(map(int, raw_point)), 10, colors[i], thickness=cv2.FILLED)\n",
    "\n",
    "    cv2.imshow(\"transform_image\", transform_image)\n",
    "\n",
    "\n",
    "def show_video():\n",
    "    video_path = \"data/video/you.mp4\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Video end\")\n",
    "            break\n",
    "\n",
    "        display(frame, \"video\")\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "def show_image():\n",
    "    # \"mat_test2.jpg\"  \"ewang.png\" \"cobra.png\"\n",
    "    image_names = [\"cobra.png\"]\n",
    "    image_path = \"../data/image/\"\n",
    "\n",
    "    for name in image_names:\n",
    "        image = cv2.imread(image_path + name, cv2.IMREAD_UNCHANGED)\n",
    "        print(image.shape)\n",
    "        display(image, name)\n",
    "\n",
    "    # 按下任意鍵則關閉所有視窗\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "show_image()\n",
    "# show_video()\n"
   ],
   "id": "7b070d45dac2571d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(720, 1280, 3)\n",
      "input [[0.7112131714820862, 0.8595473170280457], [0.45919379591941833, 0.8496631979942322]] scale [[910.3528594970703, 618.8740682601929], [587.7680587768555, 611.7575025558472]]\n",
      "unit_point [[[1159.  701.]\n",
      "  [ 378.  674.]\n",
      "  [ 436.  560.]\n",
      "  [1037.  572.]]]\n",
      "transform [array([603.9936 , 139.32652], dtype=float32), array([221.21373, 142.5154 ], dtype=float32)]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "275527ec22724824"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
